{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pprint\n",
    "import requests\n",
    "from skimage import io\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  4352  100  4352    0     0   4352      0  0:00:01  0:00:01 --:--:--     0\n"
     ]
    }
   ],
   "source": [
    "# Using Google Natural Language API to extract information from the questions\n",
    "# the following file was generated locally as Google Natural Language API can't be used in cloud notebook\n",
    "\n",
    "!curl https://www.dropbox.com/s/xcgkoohl3643mqo/train_100_keyphrases.json?dl=0 -L -o train_100_keyphrases.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'product']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_100_keyphrases = pd.read_json('train_100_keyphrases.json')\n",
    "train_100_keyphrases['keyphrases'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question_keyphrases = train_100_keyphrases['keyphrases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using Microsoft Azure Computer Vision API to extract image features\n",
    "\n",
    "subscription_key = \"my key\"  # my key\n",
    "assert subscription_key\n",
    "\n",
    "vision_base_url = \"https://westcentralus.api.cognitive.microsoft.com/vision/v1.0/\"\n",
    "vision_analyze_url = vision_base_url + \"analyze?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate an image using the Microsoft Azure Cognitive Service Computer Vision API\n",
    "def analyze_image(image_url):    \n",
    "    headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "    params = {'visualFeatures': 'Adult,Categories,Description,Color,Faces,ImageType,Tags'}\n",
    "    data = {'url': image_url}\n",
    "    \n",
    "    response = requests.post(vision_analyze_url, headers = headers, params = params, json = data)\n",
    "    response.raise_for_status()\n",
    "    analysis = response.json()\n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the Optical Character Recognition (OCR) method to detect text in an image, \n",
    "# and then extract recognized characters into a machine-usable character stream.\n",
    "\n",
    "ocr_url = vision_base_url + \"ocr\"\n",
    "def analyze_image_text(image_url):   \n",
    "    headers  = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "    params   = {'language': 'unk', 'detectOrientation ': 'true'}\n",
    "    data     = {'url': image_url}\n",
    "    \n",
    "    response = requests.post(ocr_url, headers=headers, params=params, json=data)\n",
    "    response.raise_for_status()\n",
    "    analysis = response.json()\n",
    "    \n",
    "    line_infos = [region[\"lines\"] for region in analysis[\"regions\"]]\n",
    "    word_infos = []\n",
    "    for line in line_infos:\n",
    "        for word_metadata in line:\n",
    "            for word_info in word_metadata[\"words\"]:\n",
    "                word_infos.append(word_info)\n",
    "    word_infos\n",
    "    return word_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get a list of image urls \n",
    "\n",
    "image_urllist = []\n",
    "index = [\"%.2d\" % i for i in range(100)]\n",
    "for i in index: \n",
    "    image_url = 'https://cvc.ischool.utexas.edu/~dannag/VizWiz/Images/' + 'VizWiz_train_0000000000' + str(i) + '.jpg'\n",
    "    image_urllist.append(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract image features of the given list, both image tags anad texts detected in the image\n",
    "image_rawtags = []\n",
    "image_rawtexts = []\n",
    "for i in image_urllist:\n",
    "    image_tag = analyze_image(i)\n",
    "    image_rawtags.append(image_tag['tags'])\n",
    "\n",
    "    image_text = analyze_image_text(i)\n",
    "    image_rawtexts.append(image_text)\n",
    "\n",
    "image_tags = []\n",
    "for i in image_rawtags:\n",
    "    image_tags.append([d['name'] for d in i if 'name' in d])\n",
    "\n",
    "image_texts = []\n",
    "for i in image_rawtexts:\n",
    "    image_texts.append([d['text'] for d in i if 'text' in d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B', 'sil', 'Leaves', 'OZ', '(170)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WordList(['B', 'sil']),\n",
      " WordList(['sil', 'Leaves']),\n",
      " WordList(['Leaves', 'OZ']),\n",
      " WordList(['OZ', '170'])]\n",
      "['B sil', 'sil Leaves', 'Leaves OZ', 'OZ 170']\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "joined_toblob = ' '.join(image_texts[0])\n",
    "ngrams = TextBlob(joined_toblob).ngrams(n=2)\n",
    "pprint.pprint(ngrams)\n",
    "\n",
    "joined_list = []\n",
    "for i in ngrams:\n",
    "    joined = ' '.join(i)\n",
    "    joined_list.append(joined)\n",
    "pprint.pprint(joined_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Basil', 'sil Leaves', 'Leaves OZ', 'OZ 170']\n"
     ]
    }
   ],
   "source": [
    "from autocorrect import spell\n",
    "corrected_list = []\n",
    "for i in joined_list:\n",
    "    corrected = spell(i)\n",
    "    corrected_list.append(corrected)\n",
    "print(corrected_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Basil']\n"
     ]
    }
   ],
   "source": [
    "# ['B', 'sil', 'Leaves', 'OZ', '(170)']\n",
    "# remove the non-words in corrected_list and put the corrected_list to image_text\n",
    "import enchant\n",
    "d = enchant.Dict(\"en_US\")\n",
    "corrected = []\n",
    "for i in corrected_list:\n",
    "    if d.check(i) == True:\n",
    "        corrected.append(i)\n",
    "print(corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Above shows the detailed procesure, now get a list of corrected words extracted from the OCR, \n",
    "# and append them to image_texts list\n",
    "\n",
    "import enchant\n",
    "d = enchant.Dict(\"en_US\")\n",
    "corrected_ngrams = []\n",
    "for i in image_texts:\n",
    "    joined_toblob = ' '.join(i)\n",
    "    ngram = TextBlob(joined_toblob).ngrams(n=2)\n",
    "    corrected = []\n",
    "    for k in ngram:\n",
    "        joined_k = ' '.join(k)\n",
    "        corrected_k = spell(joined_k)\n",
    "        if d.check(corrected_k) == True:\n",
    "            corrected.append(corrected_k)\n",
    "    corrected_ngrams.append(corrected)\n",
    "\n",
    "#pprint.pprint(corrected_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bottle', 'indoor', 'B', 'sil', 'Leaves', 'OZ', '(170)', 'Basil']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = []\n",
    "for a,b,c in zip(image_tags, image_texts, corrected_ngrams):\n",
    "    train_features.append(a+b+c)\n",
    "\n",
    "train_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['basil leaves',\n",
      " 'basil leaves',\n",
      " 'basil',\n",
      " 'basil',\n",
      " 'basil leaves',\n",
      " 'basil leaves',\n",
      " 'basil leaves',\n",
      " 'basil leaves',\n",
      " 'basil leaves',\n",
      " 'basil']\n"
     ]
    }
   ],
   "source": [
    "# get the majority vote of the 10 answers\n",
    "\n",
    "import pandas as pd\n",
    "df_train = pd.read_json('/Users/xuxinyi/Downloads/ML/train.json')\n",
    "rawanswers = df_train['answers']\n",
    "answers = []\n",
    "for i in rawanswers:\n",
    "    answers.append([d['answer'] for d in i])\n",
    "    \n",
    "pprint.pprint(answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'basil leaves'\n"
     ]
    }
   ],
   "source": [
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "\n",
    "major_answers = []\n",
    "for i in answers:\n",
    "    major_answers.append(most_common(i))\n",
    "    \n",
    "pprint.pprint(major_answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# using Keras, tensorflow to do the question answering task\n",
    "# ajusted from https://github.com/sujitpal/dl-models-for-qa/blob/master/src/qa-lstm-cnn.py\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input, Merge, Flatten, Dropout, concatenate\n",
    "from keras.layers import Conv1D, GlobalMaxPool1D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['What', \"'s\", 'the', 'name', 'of', 'this', 'product', '?'], ['bottle', 'indoor', 'B', 'sil', 'Leaves', 'OZ', '(170)', 'Basil']]\n"
     ]
    }
   ],
   "source": [
    "## extract training data, get train question answer pairs\n",
    "train_qapairs = []\n",
    "a = []\n",
    "# b = []\n",
    "questions = df_train['question']\n",
    "\n",
    "for question in questions:   \n",
    "    qwords = nltk.word_tokenize(question)\n",
    "    a.append([qwords])\n",
    "\n",
    "# for answer in major_answers:\n",
    "#     awords = nltk.word_tokenize(answer)\n",
    "#     b.append([awords])\n",
    "\n",
    "\n",
    "for i,j in zip(a,train_features):\n",
    "    train_qapairs.append(i+[j])\n",
    "    \n",
    "print(train_qapairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_vocab(stories, qapairs, testqs):\n",
    "    wordcounts = collections.Counter()\n",
    "    for story in stories:\n",
    "        for sword in story:\n",
    "            wordcounts[sword] += 1\n",
    "    for qapair in qapairs:\n",
    "        for qword in qapair[0]:\n",
    "            wordcounts[qword] += 1\n",
    "        for feature in qapair[1]:\n",
    "            wordcounts[feature] += 1\n",
    "    for testq in testqs:\n",
    "        for qword in testq[0]:\n",
    "            wordcounts[qword] += 1\n",
    "        for feature in testq[1]:\n",
    "            wordcounts[feature] += 1\n",
    "    words = [wordcount[0] for wordcount in wordcounts.most_common()]\n",
    "    word2idx = {w: i+1 for i, w in enumerate(words)}  # 0 = mask\n",
    "    return word2idx\n",
    "\n",
    "# Pads sequences to the same length. This function transforms a list of num_samples sequences (lists of integers) \n",
    "# into a 2D Numpy array of shape  (num_samples, num_timesteps). num_timesteps is either the maxlen argument \n",
    "# if provided, or the length of the longest sequence otherwise.\n",
    "# Sequences that are shorter than num_timesteps are padded with value at the end.\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "def vectorize_qapairs(qapairs, word2idx, seq_maxlen):\n",
    "    Xq, Xf = [], []\n",
    "    for qapair in qapairs:\n",
    "        Xq.append([word2idx[qword] for qword in qapair[0]])\n",
    "        Xf.append([word2idx[feature] for feature in qapair[1]])\n",
    "    return (pad_sequences(Xq, maxlen=seq_maxlen),\n",
    "            pad_sequences(Xf, maxlen=seq_maxlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 278)\n",
      "715\n",
      "278\n"
     ]
    }
   ],
   "source": [
    "## extract data\n",
    "import collections\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "question_maxlen = max([len(train_qapair[0]) for train_qapair in train_qapairs])\n",
    "answer_maxlen = max([len(train_qapair[1]) for train_qapair in train_qapairs])\n",
    "seq_maxlen = max([question_maxlen, answer_maxlen])\n",
    "\n",
    "word2idx = build_vocab([], train_qapairs, [])   \n",
    "vocab_size = len(word2idx) + 1 # include mask character 0\n",
    "\n",
    "Xq_train, Xf_train = vectorize_qapairs(train_qapairs, word2idx, seq_maxlen)\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "y_train = df_train['answerable'][:100]\n",
    "one_hot_labels = keras.utils.to_categorical(y_train)\n",
    "\n",
    "print(Xf_train.shape)\n",
    "print(vocab_size)\n",
    "print(seq_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  4, 48,\n",
       "        6, 32,  7,  2, 63,  1], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xq_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  26,   5, 160,\n",
       "       161, 162, 163, 164, 165], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xf_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?', 1),\n",
       " ('this', 2),\n",
       " ('is', 3),\n",
       " ('What', 4),\n",
       " ('indoor', 5),\n",
       " ('the', 6),\n",
       " ('of', 7),\n",
       " ('you', 8),\n",
       " ('in', 9),\n",
       " ('.', 10),\n",
       " ('what', 11),\n",
       " ('can', 12),\n",
       " ('to', 13),\n",
       " ('please', 14),\n",
       " ('and', 15),\n",
       " ('person', 16),\n",
       " ('I', 17),\n",
       " (',', 18),\n",
       " ('that', 19),\n",
       " ('a', 20),\n",
       " ('me', 21),\n",
       " ('on', 22),\n",
       " ('kind', 23),\n",
       " ('are', 24),\n",
       " ('/', 25),\n",
       " ('bottle', 26),\n",
       " ('Can', 27),\n",
       " ('tell', 28),\n",
       " ('for', 29),\n",
       " ('color', 30),\n",
       " ('floor', 31),\n",
       " ('name', 32),\n",
       " ('wall', 33),\n",
       " ('these', 34),\n",
       " ('close', 35),\n",
       " ('it', 36),\n",
       " ('Is', 37),\n",
       " ('or', 38),\n",
       " ('Thank', 39),\n",
       " ('hand', 40),\n",
       " ('computer', 41),\n",
       " ('does', 42),\n",
       " ('beverage', 43),\n",
       " ('Vitamin', 44),\n",
       " ('my', 45),\n",
       " ('v', 46),\n",
       " ('was', 47),\n",
       " (\"'s\", 48),\n",
       " ('electronics', 49),\n",
       " ('drink', 50),\n",
       " ('flavor', 51),\n",
       " ('blur', 52),\n",
       " ('table', 53),\n",
       " ('desk', 54),\n",
       " ('say', 55),\n",
       " ('see', 56),\n",
       " ('picture', 57),\n",
       " ('outdoor', 58),\n",
       " ('A', 59),\n",
       " ('tree', 60),\n",
       " ('Of', 61),\n",
       " ('not', 62),\n",
       " ('product', 63),\n",
       " ('up', 64),\n",
       " ('•', 65),\n",
       " ('This', 66),\n",
       " ('look', 67),\n",
       " ('food', 68),\n",
       " ('How', 69),\n",
       " ('much', 70),\n",
       " ('any', 71),\n",
       " ('right', 72),\n",
       " ('like', 73),\n",
       " ('keyboard', 74),\n",
       " ('1', 75),\n",
       " ('C', 76),\n",
       " ('Calcium', 77),\n",
       " ('type', 78),\n",
       " ('cluttered', 79),\n",
       " ('an', 80),\n",
       " ('i', 81),\n",
       " ('orange', 82),\n",
       " ('screenshot', 83),\n",
       " ('abstract', 84),\n",
       " ('Submit', 85),\n",
       " ('Click', 86),\n",
       " ('item', 87),\n",
       " ('your', 88),\n",
       " ('&', 89),\n",
       " ('600mAH', 90),\n",
       " ('When', 91),\n",
       " ('No', 92),\n",
       " ('Citrus', 93),\n",
       " ('Protection', 94),\n",
       " ('alone', 95),\n",
       " ('Keeps', 96),\n",
       " ('do', 97),\n",
       " ('cellphone', 98),\n",
       " ('black', 99),\n",
       " ('game', 100),\n",
       " ('money', 101),\n",
       " ('several', 102),\n",
       " ('anything', 103),\n",
       " ('information', 104),\n",
       " ('label', 105),\n",
       " ('device', 106),\n",
       " ('kitchen appliance', 107),\n",
       " ('movie', 108),\n",
       " ('mail', 109),\n",
       " ('when', 110),\n",
       " ('box', 111),\n",
       " ('And', 112),\n",
       " ('know', 113),\n",
       " ('if', 114),\n",
       " ('there', 115),\n",
       " ('screen', 116),\n",
       " ('CD', 117),\n",
       " ('II', 118),\n",
       " ('alcohol', 119),\n",
       " ('spice', 120),\n",
       " ('snack food', 121),\n",
       " ('day', 122),\n",
       " ('text', 123),\n",
       " ('Feature', 124),\n",
       " ('apply', 125),\n",
       " ('side', 126),\n",
       " ('cup', 127),\n",
       " ('one', 128),\n",
       " ('two', 129),\n",
       " ('Calories', 130),\n",
       " ('g', 131),\n",
       " ('Sodium', 132),\n",
       " ('2', 133),\n",
       " ('chips', 134),\n",
       " ('phone', 135),\n",
       " ('red', 136),\n",
       " ('has', 137),\n",
       " ('things', 138),\n",
       " ('GRADE', 139),\n",
       " ('jar', 140),\n",
       " ('container', 141),\n",
       " ('Hi', 142),\n",
       " ('his', 143),\n",
       " ('AIR', 144),\n",
       " ('party', 145),\n",
       " ('(2006)', 146),\n",
       " ('SCC', 147),\n",
       " ('breath', 148),\n",
       " ('recovery', 149),\n",
       " ('thing', 150),\n",
       " ('allowed', 151),\n",
       " ('5', 152),\n",
       " ('claim', 153),\n",
       " ('f', 154),\n",
       " ('very', 155),\n",
       " ('ordered', 156),\n",
       " ('M', 157),\n",
       " ('first', 158),\n",
       " ('court', 159),\n",
       " ('B', 160),\n",
       " ('sil', 161),\n",
       " ('Leaves', 162),\n",
       " ('OZ', 163),\n",
       " ('(170)', 164),\n",
       " ('Basil', 165),\n",
       " ('enchilada', 166),\n",
       " ('sauce', 167),\n",
       " ('tomatoes', 168),\n",
       " ('captcha', 169),\n",
       " ('...1.', 170),\n",
       " ('AT&T', 171),\n",
       " ('4:49', 172),\n",
       " ('PM', 173),\n",
       " ('Case', 174),\n",
       " ('insensitive', 175),\n",
       " ('müe', 176),\n",
       " ('stut', 177),\n",
       " ('Updates', 178),\n",
       " ('THAT', 179),\n",
       " ('BJ', 180),\n",
       " ('Ofofne', 181),\n",
       " ('powek', 182),\n",
       " ('Lfghtfng', 183),\n",
       " ('OLAR', 184),\n",
       " ('GARDEN', 185),\n",
       " ('LIGHT', 186),\n",
       " ('Brighten', 187),\n",
       " ('patios,', 188),\n",
       " ('decking,driveways', 189),\n",
       " ('flowerbeds', 190),\n",
       " ('Stainless', 191),\n",
       " ('Steel', 192),\n",
       " ('Construction', 193),\n",
       " ('Rechargeable', 194),\n",
       " ('IxAA', 195),\n",
       " ('Battery', 196),\n",
       " ('Included', 197),\n",
       " ('White', 198),\n",
       " ('LED', 199),\n",
       " ('Light', 200),\n",
       " ('Brighter', 201),\n",
       " ('Output', 202),\n",
       " ('Auto', 203),\n",
       " ('Sensor', 204),\n",
       " ('Turns', 205),\n",
       " ('On', 206),\n",
       " ('Dark', 207),\n",
       " ('Easy', 208),\n",
       " ('Assembly', 209),\n",
       " ('Installation', 210),\n",
       " ('Wiring,', 211),\n",
       " ('Install', 212),\n",
       " ('Anywhere', 213),\n",
       " ('equgte', 214),\n",
       " ('Compare', 215),\n",
       " ('Listerine@', 216),\n",
       " ('Active', 217),\n",
       " ('Ingredients*', 218),\n",
       " ('Advance', 219),\n",
       " ('Aitiseptic', 220),\n",
       " ('Mouthrinse', 221),\n",
       " ('e,Tartar', 222),\n",
       " ('KilS\"', 223),\n",
       " ('erms', 224),\n",
       " ('cause', 225),\n",
       " ('#æath,', 226),\n",
       " ('plaque,', 227),\n",
       " ('thä?åum', 228),\n",
       " ('disease', 229),\n",
       " ('gingivitis', 230),\n",
       " ('FighGliartar', 231),\n",
       " ('buildup', 232),\n",
       " ('better', 233),\n",
       " ('than', 234),\n",
       " ('brushing', 235),\n",
       " ('teeth', 236),\n",
       " ('cleaner', 237),\n",
       " ('brigh!er', 238),\n",
       " ('L0011012FA', 239),\n",
       " ('tartar', 240),\n",
       " ('brighter', 241),\n",
       " ('MONITOR', 242),\n",
       " ('plastic', 243),\n",
       " ('ucr', 244),\n",
       " ('0/', 245),\n",
       " (\"Far/eY'F\", 246),\n",
       " ('(2?Îkg)', 247),\n",
       " ('Surface', 248),\n",
       " ('clean', 249),\n",
       " ('kitchenware', 250),\n",
       " ('sodium', 251),\n",
       " ('content', 252),\n",
       " ('remote', 253),\n",
       " ('calculator', 254),\n",
       " ('remote control', 255),\n",
       " ('DVO&VCR', 256),\n",
       " ('bed', 257),\n",
       " ('laying', 258),\n",
       " ('bedclothes', 259),\n",
       " ('...', 260),\n",
       " ('skirt', 261),\n",
       " ('plate', 262),\n",
       " ('chocolate', 263),\n",
       " ('plant', 264),\n",
       " ('worktable', 265),\n",
       " ('ask', 266),\n",
       " ('about', 267),\n",
       " ('without', 268),\n",
       " ('taking', 269),\n",
       " ('pictures', 270),\n",
       " ('Alright', 271),\n",
       " ('appliance', 272),\n",
       " ('cooking', 273),\n",
       " ('pan', 274),\n",
       " ('RID', 275),\n",
       " ('piece', 276),\n",
       " ('who', 277),\n",
       " ('grey', 278),\n",
       " ('gray', 279),\n",
       " ('lit', 280),\n",
       " ('Am', 281),\n",
       " ('string', 282),\n",
       " ('blank', 283),\n",
       " ('night sky', 284),\n",
       " ('says', 285),\n",
       " ('e1', 286),\n",
       " ('ΙΟ', 287),\n",
       " ('here', 288),\n",
       " ('furniture', 289),\n",
       " ('nice', 290),\n",
       " ('chairs', 291),\n",
       " ('medication', 292),\n",
       " (\"'d\", 293),\n",
       " ('just', 294),\n",
       " ('dosage', 295),\n",
       " ('visible', 296),\n",
       " ('Are', 297),\n",
       " ('low', 298),\n",
       " ('cut', 299),\n",
       " ('crew', 300),\n",
       " ('Do', 301),\n",
       " ('monitor', 302),\n",
       " ('brand', 303),\n",
       " ('speakers', 304),\n",
       " ('wooden', 305),\n",
       " ('wood', 306),\n",
       " ('seasoning', 307),\n",
       " ('vegetable', 308),\n",
       " ('bar', 309),\n",
       " ('code', 310),\n",
       " ('measuring stick', 311),\n",
       " ('Forwardcr', 312),\n",
       " ('Air', 313),\n",
       " ('Bil', 314),\n",
       " ('III]', 315),\n",
       " ('il', 316),\n",
       " ('EQ0271', 317),\n",
       " ('jerky', 318),\n",
       " ('LINK', 319),\n",
       " ('S.', 320),\n",
       " ('LINKS', 321),\n",
       " ('wait', 322),\n",
       " ('2F#', 323),\n",
       " ('eaten', 324),\n",
       " ('hers', 325),\n",
       " ('rom', 326),\n",
       " ('EIN?', 327),\n",
       " ('toothbrush', 328),\n",
       " ('Does', 329),\n",
       " ('back', 330),\n",
       " ('show', 331),\n",
       " ('languages', 332),\n",
       " ('supported', 333),\n",
       " ('Music', 334),\n",
       " ('Viüeo', 335),\n",
       " (\"-'An\", 336),\n",
       " ('exhilarating', 337),\n",
       " (\"gift'\", 338),\n",
       " ('\"Viola', 339),\n",
       " ('Davi', 340),\n",
       " ('awards-wo', 341),\n",
       " ('—', 342),\n",
       " ('Alynda', 343),\n",
       " ('Wheat,', 344),\n",
       " ('Widescreen', 345),\n",
       " ('(1.\"1)', 346),\n",
       " ('Time', 347),\n",
       " ('Av.r.', 348),\n",
       " ('14b', 349),\n",
       " ('specifications', 350),\n",
       " ('G,', 351),\n",
       " ('elemr', 352),\n",
       " ('•.,aste', 353),\n",
       " ('haste', 354),\n",
       " ('little', 355),\n",
       " ('green', 356),\n",
       " ('dining table', 357),\n",
       " ('yogurt', 358),\n",
       " ('cookie', 359),\n",
       " ('dough', 360),\n",
       " ('USDA', 361),\n",
       " ('CHOICE', 362),\n",
       " ('Sl', 363),\n",
       " ('RLOIN', 364),\n",
       " ('.STuA', 365),\n",
       " (\"l.tN11ANC'L1)\", 366),\n",
       " ('WITH', 367),\n",
       " ('UP', 368),\n",
       " ('TO', 369),\n",
       " ('12%', 370),\n",
       " ('OF', 371),\n",
       " (',SOI.U', 372),\n",
       " ('cttogc.•e', 373),\n",
       " ('ot', 374),\n",
       " ('STEAKS', 375),\n",
       " ('Choicest', 376),\n",
       " ('WITHOUT', 377),\n",
       " ('UNTO', 378),\n",
       " ('card', 379),\n",
       " ('upside', 380),\n",
       " ('down', 381),\n",
       " ('Who', 382),\n",
       " ('clipart', 383),\n",
       " ('coffee', 384),\n",
       " ('Please', 385),\n",
       " ('describe', 386),\n",
       " ('pattern', 387),\n",
       " ('bag', 388),\n",
       " ('fabric', 389),\n",
       " ('Test', 390),\n",
       " ('test', 391),\n",
       " ('sitting', 392),\n",
       " ('white', 393),\n",
       " ('mouse', 394),\n",
       " ('لامنانun', 395),\n",
       " ('اا', 396),\n",
       " ('CCCCCZ', 397),\n",
       " ('CÜCCCCCCC', 398),\n",
       " ('CCCCCECC', 399),\n",
       " ('e', 400),\n",
       " ('CCCCCCCC', 401),\n",
       " ('ECCCCCCC\"', 402),\n",
       " ('read', 403),\n",
       " ('syrup', 404),\n",
       " ('Amount', 405),\n",
       " ('Teneur', 406),\n",
       " ('IZ', 407),\n",
       " ('Fat', 408),\n",
       " ('Lipides', 409),\n",
       " ('O', 410),\n",
       " ('Saturated', 411),\n",
       " ('saturés', 412),\n",
       " ('+', 413),\n",
       " ('Trans', 414),\n",
       " ('Cholesterol', 415),\n",
       " ('So€turn', 416),\n",
       " ('15', 417),\n",
       " ('Carbohydrate', 418),\n",
       " ('Fibre', 419),\n",
       " ('Fibres', 420),\n",
       " ('Sugars', 421),\n",
       " ('Sctes', 422),\n",
       " ('22', 423),\n",
       " ('Protein', 424),\n",
       " ('Protéines', 425),\n",
       " ('Vta—ine', 426),\n",
       " ('Vtani-é', 427),\n",
       " ('Caen', 428),\n",
       " ('!', 429),\n",
       " ('Fer', 430),\n",
       " ('saturated', 431),\n",
       " ('Carbohydrates', 432),\n",
       " ('leg', 433),\n",
       " ('stuffed', 434),\n",
       " ('colored', 435),\n",
       " ('GARDENoJEAT1tc.', 436),\n",
       " ('BLUi', 437),\n",
       " ('CHIPS', 438),\n",
       " ('Corn', 439),\n",
       " (\"'IOrt[tta\", 440),\n",
       " ('Chips', 441),\n",
       " ('MADE', 442),\n",
       " ('ORGANIC', 443),\n",
       " ('BLUE', 444),\n",
       " ('got', 445),\n",
       " ('stuff', 446),\n",
       " ('shelf', 447),\n",
       " ('u»pwvJ', 448),\n",
       " ('expire', 449),\n",
       " ('diuO', 450),\n",
       " ('instant', 451),\n",
       " ('cook', 452),\n",
       " ('serve', 453),\n",
       " ('pudding', 454),\n",
       " ('canned', 455),\n",
       " ('good', 456),\n",
       " ('display', 457),\n",
       " ('dark', 458),\n",
       " ('expiration', 459),\n",
       " ('date', 460),\n",
       " ('Publix', 461),\n",
       " ('ULTRA-PASTEURIZED', 462),\n",
       " ('coffeecreamer', 463),\n",
       " ('ONE', 464),\n",
       " ('ALONE', 465),\n",
       " ('Ok', 466),\n",
       " ('hope', 467),\n",
       " ('works', 468),\n",
       " ('time', 469),\n",
       " ('soup', 470),\n",
       " ('called', 471),\n",
       " ('-들=', 472),\n",
       " ('would', 473),\n",
       " ('contains', 474),\n",
       " ('Good', 475),\n",
       " ('morning', 476),\n",
       " ('could', 477),\n",
       " ('Thanks', 478),\n",
       " ('assistance', 479),\n",
       " ('soda', 480),\n",
       " ('7-up', 481),\n",
       " ('soft drink', 482),\n",
       " ('Speedo', 483),\n",
       " ('logo', 484),\n",
       " ('swimming', 485),\n",
       " ('hat', 486),\n",
       " ('leather', 487),\n",
       " ('front', 488),\n",
       " ('feet', 489),\n",
       " ('staring', 490),\n",
       " ('-', 491),\n",
       " ('light', 492),\n",
       " ('lamp', 493),\n",
       " ('am', 494),\n",
       " ('looking', 495),\n",
       " ('at', 496),\n",
       " ('entertainment center', 497),\n",
       " ('charge', 498),\n",
       " ('service', 499),\n",
       " ('porch', 500),\n",
       " ('shirt', 501),\n",
       " ('clothing', 502),\n",
       " ('curtain', 503),\n",
       " ('favorite', 504),\n",
       " ('dog', 505),\n",
       " ('island', 506),\n",
       " ('holding', 507),\n",
       " ('ث', 508),\n",
       " ('headphones', 509),\n",
       " ('photo', 510),\n",
       " ('cabinet', 511),\n",
       " ('kitchen', 512),\n",
       " ('counter', 513),\n",
       " ('oven', 514),\n",
       " ('Guy', 515),\n",
       " ('sky', 516),\n",
       " ('way', 517),\n",
       " ('road', 518),\n",
       " ('long', 519),\n",
       " ('lined', 520),\n",
       " ('highway', 521),\n",
       " ('blue', 522),\n",
       " ('contents', 523),\n",
       " ('tube', 524),\n",
       " ('N', 525),\n",
       " ('A*', 526),\n",
       " ('17', 527),\n",
       " ('Na', 528),\n",
       " ('where', 529),\n",
       " ('water', 530),\n",
       " ('come', 531),\n",
       " ('from', 532),\n",
       " ('drinking water', 533),\n",
       " ('aww,', 534),\n",
       " ('wnmww;', 535),\n",
       " ('ÄREZife', 536),\n",
       " ('page', 537),\n",
       " ('have', 538),\n",
       " ('scanned', 539),\n",
       " ('with', 540),\n",
       " ('camera', 541),\n",
       " ('newspaper', 542),\n",
       " ('document', 543),\n",
       " ('tgh', 544),\n",
       " ('Pearey', 545),\n",
       " ('lull,', 546),\n",
       " ('19S2', 547),\n",
       " ('Del', 548),\n",
       " ('120.', 549),\n",
       " ('refund', 550),\n",
       " ('benefits', 551),\n",
       " ('obtained.', 552),\n",
       " ('De-Smet', 553),\n",
       " ('(f', 554),\n",
       " ('253,', 555),\n",
       " (\"'*here\", 556),\n",
       " ('repudiating', 557),\n",
       " ('rds', 558),\n",
       " ('purchase', 559),\n",
       " ('solvent', 560),\n",
       " ('extraction', 561),\n",
       " ('Ot', 562),\n",
       " ('earnest.', 563),\n",
       " ('Delhi,', 564),\n",
       " ('S', 565),\n",
       " ('603.', 566),\n",
       " ('fie', 567),\n",
       " ('Contract', 568),\n",
       " ('Act', 569),\n",
       " ('affords.', 570),\n",
       " ('Some', 571),\n",
       " ('other', 572),\n",
       " ('retredies', 573),\n",
       " ('J.', 574),\n",
       " ('1963,', 575),\n",
       " ('e.g.,', 576),\n",
       " ('injunction', 577),\n",
       " ('prevent', 578),\n",
       " (\"c'\", 579),\n",
       " ('action', 580),\n",
       " ('specific', 581),\n",
       " ('IS,', 582),\n",
       " ('(1909)', 583),\n",
       " ('34', 584),\n",
       " ('Bom', 585),\n",
       " ('192;', 586),\n",
       " ('Finday', 587),\n",
       " ('Muir', 588),\n",
       " ('Co', 589),\n",
       " ('_', 590),\n",
       " ('—y', 591),\n",
       " ('•covery', 592),\n",
       " ('injured', 593),\n",
       " ('should', 594),\n",
       " ('meet', 595),\n",
       " ('requirement', 596),\n",
       " ('by', 597),\n",
       " ('te', 598),\n",
       " ('Bank', 599),\n",
       " ('Saurashtra', 600),\n",
       " ('PNB,', 601),\n",
       " ('(2001)', 602),\n",
       " ('751:', 603),\n",
       " ('securities', 604),\n",
       " ('upheld.', 605),\n",
       " ('There', 606),\n",
       " ('Yvad', 607),\n",
       " ('already', 608),\n",
       " ('paid', 609),\n",
       " ('price', 610),\n",
       " ('bank.', 611),\n",
       " ('The', 612),\n",
       " ('latter', 613),\n",
       " ('easonable', 614),\n",
       " ('amount', 615),\n",
       " ('compensation.', 616),\n",
       " ('Gunv', 617),\n",
       " ('Guj', 618),\n",
       " ('(Guj),', 619),\n",
       " ('original', 620),\n",
       " ('available,', 621),\n",
       " ('abrupt', 622),\n",
       " ('shift', 623),\n",
       " ('loss', 624),\n",
       " ('allowed.', 625),\n",
       " ('C.', 626),\n",
       " ('Panduranga', 627),\n",
       " ('Rae', 628),\n",
       " ('fic', 629),\n",
       " ('reco', 630),\n",
       " ('property', 631),\n",
       " ('n', 632),\n",
       " ('favozr', 633),\n",
       " ('readiness', 634),\n",
       " ('willingness', 635),\n",
       " ('pay.', 636),\n",
       " ('Data', 637),\n",
       " ('gam', 638),\n",
       " ('Ltd.', 639),\n",
       " ('126', 640),\n",
       " ('DI-T', 641),\n",
       " ('617', 642),\n",
       " ('(Del).', 643),\n",
       " ('writ', 644),\n",
       " ('•each', 645),\n",
       " ('contract', 646),\n",
       " ('gives', 647),\n",
       " ('rise', 648),\n",
       " ('number', 649),\n",
       " ('darnage.', 650),\n",
       " ('etc.', 651),\n",
       " ('case', 652),\n",
       " ('involved', 653),\n",
       " ('guar', 654),\n",
       " ('ty', 655),\n",
       " ('unic', 656),\n",
       " ('ipat', 657),\n",
       " ('Council', 658),\n",
       " ('SA-', 659),\n",
       " ('clairnant', 660),\n",
       " ('breach', 661),\n",
       " ('part', 662),\n",
       " ('sub—standar', 663),\n",
       " ('d', 664),\n",
       " ('rnac', 665),\n",
       " ('hi', 666),\n",
       " ('nery', 667),\n",
       " ('w', 668),\n",
       " ('as', 669),\n",
       " ('SUPP', 670),\n",
       " ('lied', 671),\n",
       " ('opinion', 672),\n",
       " ('taken.', 673),\n",
       " ('hence', 674),\n",
       " ('evidence', 675),\n",
       " ('DJS', 676),\n",
       " ('to-cd.', 677),\n",
       " ('441.', 678),\n",
       " ('seller', 679),\n",
       " ('resold', 680),\n",
       " ('another,', 681),\n",
       " ('J', 682),\n",
       " ('996)', 683),\n",
       " ('surn', 684),\n",
       " ('rncant', 685),\n",
       " ('fJJrn', 686),\n",
       " (\"'e\", 687),\n",
       " ('had', 688),\n",
       " ('erne', 689),\n",
       " ('t', 690),\n",
       " ('ud.', 691),\n",
       " ('s', 692),\n",
       " ('scW', 693),\n",
       " ('Sec', 694),\n",
       " ('•y.', 695),\n",
       " ('wards', 696),\n",
       " ('inaction', 697),\n",
       " ('uninjured', 698),\n",
       " ('byte', 699),\n",
       " ('waste', 700),\n",
       " ('tooth', 701),\n",
       " ('floss', 702),\n",
       " ('today', 703),\n",
       " ('off', 704),\n",
       " ('guard', 705),\n",
       " ('Chi', 706),\n",
       " ('council', 707),\n",
       " ('Supplied', 708),\n",
       " ('VJ', 709),\n",
       " ('absurd', 710),\n",
       " ('thud', 711),\n",
       " ('Tell', 712),\n",
       " ('Scea', 713),\n",
       " ('ng', 714)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "sorted_word2idx = sorted(word2idx.items(), key=operator.itemgetter(1))\n",
    "sorted_word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.109375    0.140625   -0.03173828 ...  0.00765991  0.12011719\n",
      "  -0.1796875 ]\n",
      " ...\n",
      " [-0.04125977 -0.20800781  0.06445312 ... -0.18457031  0.17871094\n",
      "  -0.00747681]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.08203125  0.31640625  0.12792969 ... -0.18847656  0.10546875\n",
      "   0.359375  ]]\n"
     ]
    }
   ],
   "source": [
    "# get embeddings from word2vec\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "WORD2VEC_EMBED_SIZE = 300 \n",
    "# why 300? According to research, the quality for vector representations improves as you increase the vector size \n",
    "# until you reach 300 dimensions.  http://www.aclweb.org/anthology/D14-1162\n",
    "\n",
    "word2vec = KeyedVectors.load_word2vec_format(\n",
    "    '/Users/xuxinyi/Downloads/ML/GoogleNews-vectors-negative300.bin.gz', binary=True)  \n",
    "embedding_weights = np.zeros((vocab_size, WORD2VEC_EMBED_SIZE))\n",
    "for word, index in word2idx.items():\n",
    "    try:\n",
    "        embedding_weights[index, :] = word2vec[word.lower()]\n",
    "    except KeyError:\n",
    "        pass  # keep as zero (not ideal, but what else can we do?)\n",
    "    \n",
    "print(embedding_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(715, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_weights.shape\n",
    "# why later it runs error? \n",
    "# ValueError: Layer weight shape (162, 300) not compatible with provided weight shape (716, 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 278, 300)          214500    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 278, 128)          219648    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 278, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 274, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 137, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 137, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 17536)             0         \n",
      "=================================================================\n",
      "Total params: 516,196\n",
      "Trainable params: 516,196\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 278, 300)          214500    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 278, 128)          219648    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 278, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 274, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 137, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 137, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 17536)             0         \n",
      "=================================================================\n",
      "Total params: 516,196\n",
      "Trainable params: 516,196\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_1 (Merge)              (None, 35072)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 70146     \n",
      "=================================================================\n",
      "Total params: 1,102,538\n",
      "Trainable params: 1,102,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "# build model, add LSTM and CNN layers\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input, Merge, Flatten, Dropout, concatenate\n",
    "from keras.layers import Conv1D, MaxPooling1D, LSTM\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "\n",
    "QA_EMBED_SIZE = 128\n",
    "qenc = Sequential()\n",
    "qenc.add(Embedding(output_dim=WORD2VEC_EMBED_SIZE, input_dim=vocab_size,\n",
    "                   input_length=seq_maxlen,\n",
    "                   weights=[embedding_weights]))     ### notice embedding_weights\n",
    "qenc.add(LSTM(QA_EMBED_SIZE, return_sequences=True))\n",
    "qenc.add(Dropout(0.3))\n",
    "qenc.add(Conv1D(QA_EMBED_SIZE, kernel_size = 5, padding='valid'))# the quotient in which the digits after the decimal point are removed\n",
    "qenc.add(MaxPooling1D(pool_size=2, padding='valid'))\n",
    "qenc.add(Dropout(0.3))\n",
    "qenc.add(Flatten())\n",
    "print(qenc.summary())\n",
    "\n",
    "fenc = Sequential()\n",
    "fenc.add(Embedding(output_dim=WORD2VEC_EMBED_SIZE, input_dim=vocab_size,\n",
    "                   input_length=seq_maxlen,\n",
    "                   weights=[embedding_weights]))\n",
    "fenc.add(LSTM(QA_EMBED_SIZE, return_sequences=True))\n",
    "fenc.add(Dropout(0.3))\n",
    "fenc.add(Conv1D(QA_EMBED_SIZE, kernel_size = 5, padding='valid'))\n",
    "fenc.add(MaxPooling1D(pool_size=2, padding='valid'))\n",
    "fenc.add(Dropout(0.3))\n",
    "fenc.add(Flatten())\n",
    "print(fenc.summary())\n",
    "\n",
    "model = Sequential()\n",
    "# keras.layers.Concatenate(axis=-1)\n",
    "model.add(Merge([qenc, fenc], mode=\"concat\", concat_axis=-1))\n",
    "model.add(Dense(2, activation=\"sigmoid\")) \n",
    "# change activation from softmax to relu, the loss is suddenly decrease and the accuracy is no longer 0.656\n",
    "\n",
    "model.compile(optimizer='adam', loss=\"categorical_crossentropy\",    # loss=\"categorical_crossentropy\"  error, see description\n",
    "              metrics=[\"accuracy\"])                            # optimizer='rmsprop' < optimizer=\"adam\"\n",
    "print(model.summary())\n",
    "\n",
    "### Use 'softmax' and 'categorical_crossentropy' instead of 'sigmoid' and 'binary_crossentropy'. \n",
    "### By using the latter two, you're treating the problem as a multilabel problem, not a multiclass problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 0.6724 - acc: 0.6100\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.6608 - acc: 0.6500\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.6556 - acc: 0.6500\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.6724 - acc: 0.6500\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.6578 - acc: 0.6500\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.6438 - acc: 0.6500\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.6559 - acc: 0.6500\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.6332 - acc: 0.6500\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.6638 - acc: 0.6600\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.6727 - acc: 0.6600\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.6448 - acc: 0.6500\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.6605 - acc: 0.6500\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.6195 - acc: 0.7200\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.5423 - acc: 0.7100\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.4894 - acc: 0.7600\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.3723 - acc: 0.8200\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.3331 - acc: 0.8500\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.2908 - acc: 0.8800\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.2327 - acc: 0.8900\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.1930 - acc: 0.9100\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.2045 - acc: 0.9000\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.1275 - acc: 0.9600\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.1222 - acc: 0.9700\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0690 - acc: 0.9800\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.0637 - acc: 0.9900\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.0561 - acc: 0.9900\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0411 - acc: 0.9800\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0492 - acc: 0.9800\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.0260 - acc: 0.9900\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.0225 - acc: 0.9900\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.0199 - acc: 0.9900\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.0686 - acc: 0.9800\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0283 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0170 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0112 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.0131 - acc: 0.9900\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.0156 - acc: 0.9900\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0096 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 5s 48ms/step - loss: 0.0129 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 0.0136 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.0087 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.0114 - acc: 0.9900\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0145 - acc: 0.9900\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.0627 - acc: 0.9600\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.1055 - acc: 0.9500\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0101 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x129996898>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint = ModelCheckpoint(\n",
    "#     filepath=os.path.join(MODEL_DIR, \"qa-lstm-cnn-best.hdf5\"),\n",
    "#     verbose=1, save_best_only=True)\n",
    "BATCH_SIZE = 32\n",
    "NBR_EPOCHS = 50\n",
    "model.fit([Xq_train, Xf_train], one_hot_labels, batch_size=BATCH_SIZE,    ### notice fit both Xqtrain and Xatrain\n",
    "          epochs=NBR_EPOCHS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare the X_test data\n",
    "image_urllist = []\n",
    "index = [\"%.2d\" % i for i in range(30)]\n",
    "for i in index: \n",
    "    image_url = 'https://cvc.ischool.utexas.edu/~dannag/VizWiz/Images/' + 'VizWiz_test_0000000200' + str(i) + '.jpg'\n",
    "    image_urllist.append(image_url)\n",
    "\n",
    "# extract image features of the given list, both image tags anad texts detected in the image\n",
    "image_rawtags = []\n",
    "image_rawtexts = []\n",
    "for i in image_urllist:\n",
    "    image_tag = analyze_image(i)\n",
    "    image_rawtags.append(image_tag['tags'])\n",
    "\n",
    "    image_text = analyze_image_text(i)\n",
    "    image_rawtexts.append(image_text)\n",
    "\n",
    "image_tags = []\n",
    "for i in image_rawtags:\n",
    "    image_tags.append([d['name'] for d in i if 'name' in d])\n",
    "\n",
    "image_texts = []\n",
    "for i in image_rawtexts:\n",
    "    image_texts.append([d['text'] for d in i if 'text' in d])\n",
    "    \n",
    "from textblob import TextBlob\n",
    "joined_toblob = ' '.join(image_texts[0])\n",
    "ngrams = TextBlob(joined_toblob).ngrams(n=2)\n",
    "\n",
    "joined_list = []\n",
    "for i in ngrams:\n",
    "    joined = ' '.join(i)\n",
    "    joined_list.append(joined)\n",
    "\n",
    "from autocorrect import spell\n",
    "corrected_list = []\n",
    "for i in joined_list:\n",
    "    corrected = spell(i)\n",
    "    corrected_list.append(corrected)\n",
    "import enchant\n",
    "d = enchant.Dict(\"en_US\")\n",
    "corrected = []\n",
    "for i in corrected_list:\n",
    "    if d.check(i) == True:\n",
    "        corrected.append(i)\n",
    "\n",
    "import enchant\n",
    "d = enchant.Dict(\"en_US\")\n",
    "corrected_ngrams = []\n",
    "for i in image_texts:\n",
    "    joined_toblob = ' '.join(i)\n",
    "    ngram = TextBlob(joined_toblob).ngrams(n=2)\n",
    "    corrected = []\n",
    "    for k in ngram:\n",
    "        joined_k = ' '.join(k)\n",
    "        corrected_k = spell(joined_k)\n",
    "        if d.check(corrected_k) == True:\n",
    "            corrected.append(corrected_k)\n",
    "    corrected_ngrams.append(corrected)\n",
    "    \n",
    "test_features = []\n",
    "for a,b,c in zip(image_tags, image_texts, corrected_ngrams):\n",
    "    test_features.append(a+b+c)\n",
    "\n",
    "## extract training data, get train question answer pairs\n",
    "df_test = pd.read_json('/Users/xuxinyi/Downloads/ML/test.json')\n",
    "\n",
    "testqs = []\n",
    "a = []\n",
    "questions = df_test['question']\n",
    "\n",
    "for question in questions:   \n",
    "    qwords = nltk.word_tokenize(question)\n",
    "    a.append([qwords])\n",
    "\n",
    "for i,j in zip(a,test_features):\n",
    "    testqs.append(i+[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 278)\n",
      "278\n"
     ]
    }
   ],
   "source": [
    "# question_maxlen = max([len(testqs[0]) for testq in testqs])\n",
    "# answer_maxlen = max([len(test_qapair[1]) for test_qapair in test_qapairs])\n",
    "# seq_maxlen = question_maxlen\n",
    "\n",
    "word2idx = build_vocab([],[], testqs)   \n",
    "vocab_size = len(word2idx) + 1 # include mask character 0\n",
    "\n",
    "seq_maxlen =278\n",
    "def vectorize_testqs(testqs, word2idx, seq_maxlen):\n",
    "    Xq, Xf = [], []\n",
    "    for testq in testqs:\n",
    "        Xq.append([word2idx[qword] for qword in testq[0]])\n",
    "        Xf.append([word2idx[feature] for feature in testq[1]])\n",
    "    return (pad_sequences(Xq, maxlen=seq_maxlen),\n",
    "            pad_sequences(Xf, maxlen=seq_maxlen))\n",
    "\n",
    "Xq_test, Xf_test = vectorize_testqs(testqs, word2idx, seq_maxlen)\n",
    "\n",
    "print(Xf_test.shape)\n",
    "print(seq_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"Evaluation...\")\n",
    "# loss, acc = model.evaluate([Xqtest, Xatest], Ytest, batch_size=BATCH_SIZE)\n",
    "# print(\"Test loss/accuracy final model = %.4f, %.4f\" % (loss, acc))\n",
    "\n",
    "# model.save_weights(os.path.join(MODEL_DIR, \"qa-lstm-attn-final.hdf5\"))\n",
    "# with open(os.path.join(MODEL_DIR, \"qa-lstm-attn.json\"), \"wb\") as fjson:\n",
    "#     fjson.write(model.to_json())\n",
    "\n",
    "# model.load_weights(filepath=os.path.join(MODEL_DIR, \n",
    "#                                          \"qa-lstm-attn-best.hdf5\"))\n",
    "# loss, acc = model.evaluate([Xqtest, Xatest], Ytest, batch_size=BATCH_SIZE)\n",
    "# print(\"Test loss/accuracy best model = %.4f, %.4f\" % (loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.3643175e-04 9.9808758e-01]\n",
      " [7.7132356e-01 8.2058437e-02]\n",
      " [1.5007910e-08 1.0000000e+00]\n",
      " [9.4667518e-01 1.5575873e-02]\n",
      " [4.4975374e-02 8.7884325e-01]\n",
      " [9.8537016e-01 4.4306829e-03]\n",
      " [7.3010311e-02 8.2579619e-01]\n",
      " [5.6172784e-02 8.4647238e-01]\n",
      " [4.3406408e-02 8.8014656e-01]\n",
      " [7.7138585e-01 8.5565098e-02]\n",
      " [8.1453407e-01 6.2369730e-02]\n",
      " [3.6071464e-02 8.9638603e-01]\n",
      " [5.5535417e-02 8.4816688e-01]\n",
      " [3.1519797e-01 4.1519490e-01]\n",
      " [2.3502968e-01 5.1171148e-01]\n",
      " [9.9977559e-01 5.6821475e-05]\n",
      " [2.3827709e-03 9.9372971e-01]\n",
      " [4.8970247e-05 9.9988270e-01]\n",
      " [9.3680501e-07 9.9999845e-01]\n",
      " [3.9457764e-02 8.8896614e-01]\n",
      " [2.8829006e-03 9.9285114e-01]\n",
      " [9.1051632e-01 2.7507091e-02]\n",
      " [7.5852475e-04 9.9852604e-01]\n",
      " [9.9437124e-01 1.5875258e-03]\n",
      " [9.9191898e-01 2.1879070e-03]\n",
      " [9.2385424e-09 1.0000000e+00]\n",
      " [3.4978703e-04 9.9918133e-01]\n",
      " [2.8292960e-02 9.2531145e-01]\n",
      " [4.2356560e-03 9.8897237e-01]\n",
      " [8.4776685e-02 7.7939260e-01]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict([Xq_test, Xf_test], batch_size = BATCH_SIZE)\n",
    "print(y_pred)\n",
    "# sample_submission = pd.read_csv(\"../sample_submission.csv\")\n",
    "# sample_submission['answerable'] = y_test\n",
    "# sample_submission.to_csv(\"predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.000836431747302413, 0.9980875849723816],\n",
      " [0.771323561668396, 0.08205843716859818],\n",
      " [1.5007909581754575e-08, 1.0],\n",
      " [0.946675181388855, 0.015575872734189034],\n",
      " [0.04497537389397621, 0.8788432478904724],\n",
      " [0.9853701591491699, 0.004430682864040136],\n",
      " [0.07301031053066254, 0.8257961869239807],\n",
      " [0.05617278441786766, 0.8464723825454712],\n",
      " [0.0434064082801342, 0.8801465630531311],\n",
      " [0.7713858485221863, 0.08556509763002396],\n",
      " [0.814534068107605, 0.062369730323553085],\n",
      " [0.03607146441936493, 0.8963860273361206],\n",
      " [0.055535417050123215, 0.8481668829917908],\n",
      " [0.31519797444343567, 0.41519489884376526],\n",
      " [0.2350296825170517, 0.5117114782333374],\n",
      " [0.9997755885124207, 5.682147457264364e-05],\n",
      " [0.0023827708791941404, 0.9937297105789185],\n",
      " [4.8970247007673606e-05, 0.999882698059082],\n",
      " [9.368050086777657e-07, 0.9999984502792358],\n",
      " [0.039457764476537704, 0.8889661431312561],\n",
      " [0.002882900647819042, 0.9928511381149292],\n",
      " [0.9105163216590881, 0.02750709094107151],\n",
      " [0.000758524751290679, 0.9985260367393494],\n",
      " [0.994371235370636, 0.0015875258250162005],\n",
      " [0.9919189810752869, 0.0021879069972783327],\n",
      " [9.23854237555588e-09, 1.0],\n",
      " [0.0003497870347928256, 0.99918133020401],\n",
      " [0.028292959555983543, 0.9253114461898804],\n",
      " [0.004235656000673771, 0.9889723658561707],\n",
      " [0.08477668464183807, 0.7793926000595093]]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(y_pred.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,\n",
      " 0,\n",
      " 1,\n",
      " 0,\n",
      " 1,\n",
      " 0,\n",
      " 1,\n",
      " 1,\n",
      " 1,\n",
      " 0,\n",
      " 0,\n",
      " 1,\n",
      " 1,\n",
      " 0,\n",
      " 1,\n",
      " 0,\n",
      " 1,\n",
      " 1,\n",
      " 1,\n",
      " 1,\n",
      " 1,\n",
      " 0,\n",
      " 1,\n",
      " 0,\n",
      " 0,\n",
      " 1,\n",
      " 1,\n",
      " 1,\n",
      " 1,\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "pred_answerable = []\n",
    "for i in y_pred:\n",
    "    pred = i[1]\n",
    "    if pred > 0.5:\n",
    "        pred = 1\n",
    "    else:\n",
    "        pred = 0\n",
    "    pred_answerable.append(pred)\n",
    "\n",
    "pprint.pprint(pred_answerable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
